{
    "mode": "train",
    "device": "cuda",
    "log_dir": "/home/zhehui/llm_tool/rt1_pytorch/mnt/logs_1",
    "time_sequence_length": 2,
    "lr": 0.0001,
    "batch_size": 3,
    "epochs": 50,
    "resume": false,
    "resume_from_checkpoint": "",
    "predicting_next_ts": true,
    "world_size": 4,
    "dist_url": "env://",
    "val_interval" : 25,
    "num_val_threads": 25,
    "num_train_episode" : 200,
    "num_val_episode" : 10,
    "using_proprioception" : false,
    "network_configs": {
        "vocab_size" : 256,
        "token_embedding_size_per_image" : 512,
        "num_layers" : 4,
        "layer_size" : 128,
        "num_heads" : 4,
        "feed_forward_size" : 128,
        "dropout_rate" : 0.1,
        "crop_size" : 236,
        "use_token_learner" : true
    },
    "scheduler_configs" : {
        "T_0" : 10,
        "T_mult" : 2,
        "eta_min" : 1e-6,
        "verbose" : true
    }

}